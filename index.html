<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1.0, user-scalable=no"
    />
    <title>Assistive AI</title>
    <style>
      /* ... existing style ... */
      #listenButton:disabled {
        background-color: #4b5563; /* Gray */
        opacity: 0.5;
        cursor: not-allowed;
      }
      /* ... existing style ... */
    </style>
  </head>
  <body
    style="
      background-color: #000;
      color: #fff;
      font-family: sans-serif;
      overflow: hidden;
      margin: 0;
    "
  >
    <!-- THIS IS THE FIX: Added crossorigin="anonymous" -->
    <img
      id="esp32Feed"
      crossorigin="anonymous"
      alt="Camera Feed"
      style="
        position: fixed;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
        object-fit: cover;
        z-index: -1;
        opacity: 0.3;
      "
    />

    <canvas id="captureCanvas" style="display: none"></canvas>

    <div
      style="
        display: flex;
        flex-direction: column;
        height: 100vh;
        justify-content: space-between;
        align-items: center;
        padding: 32px;
      "
    >
      <div
        id="status"
        style="
          font-size: 1.5rem;
          font-weight: 500;
          text-align: center;
          height: 80px;
        "
      >
        Initializing system...
      </div>

      <div style="display: flex; justify-content: center; align-items: center">
        <button
          id="listenButton"
          disabled
          style="
            background-color: #2563eb;
            color: white;
            border-radius: 9999px;
            width: 160px;
            height: 160px;
            display: flex;
            justify-content: center;
            align-items: center;
            box-shadow: 0 10px 15px -3px rgba(0, 0, 0, 0.1),
              0 4px 6px -2px rgba(0, 0, 0, 0.05);
            border: none;
            transition: all 0.2s ease;
          "
        >
          <svg
            xmlns="http://www.w3.org/2000/svg"
            id="micIcon"
            style="width: 80px; height: 80px"
            viewBox="0 0 24 24"
            fill="currentColor"
          >
            <path
              d="M12 14c1.66 0 2.99-1.34 2.99-3L15 5c0-1.66-1.34-3-3-3S9 3.34 9 5v6c0 1.66 1.34 3 3 3zm5.3-3c0 3-2.54 5.1-5.3 5.1S6.7 14 6.7 11H5c0 3.41 2.72 6.23 6 6.72V21h2v-3.28c3.28-.49 6-3.31 6-6.72h-1.7z"
            />
          </svg>
        </button>
      </div>
    </div>

    <script>
      // === CONFIG ===
      const SERVER_BASE_URL = "http://10.248.176.27:8000";
      const SERVER_API_URL = `${SERVER_BASE_URL}/api/analyze`;
      // Route video through our proxy to avoid CORS/tainted canvas
      const PROXIED_STREAM_URL = `${SERVER_BASE_URL}/camera_stream`;

      // ... (rest of the script is unchanged) ...
      const esp32Feed = document.getElementById("esp32Feed");
      const canvas = document.getElementById("captureCanvas");
      const listenButton = document.getElementById("listenButton");
      const statusDiv = document.getElementById("status");
      const micIcon = document.getElementById("micIcon");

      let recognition;
      let isListening = false;
      let isSystemReady = false;

      function speak(text) {
        console.log("Speaking:", text);
        statusDiv.textContent = text;
        const utterance = new SpeechSynthesisUtterance(text);
        utterance.lang = "en-US";
        speechSynthesis.speak(utterance);
      }

      function initSpeechRecognition() {
        const SpeechRecognition =
          window.SpeechRecognition || window.webkitSpeechRecognition;
        if (!SpeechRecognition) {
          speak(
            "Error: Speech recognition is not supported in this browser. Please use Chrome on Android."
          );
          return;
        }
        recognition = new SpeechRecognition();
        recognition.continuous = false;
        recognition.interimResults = false;
        recognition.lang = "en-US";

        recognition.onresult = (event) => {
          const command = event.results[0][0].transcript.toLowerCase().trim();
          console.log("Command heard:", command);
          statusDiv.textContent = ` Heard: "${command}"`;
          processCommand(command);
        };

        recognition.onend = () => {
          isListening = false;
          listenButton.classList.remove("listening");
          micIcon.innerHTML = `<path d="M12 14c1.66 0 2.99-1.34 2.99-3L15 5c0-1.66-1.34-3-3-3S9 3.34 9 5v6c0 1.66 1.34 3 3 3zm5.3-3c0 3-2.54 5.1-5.3 5.1S6.7 14 6.7 11H5c0 3.41 2.72 6.23 6 6.72V21h2v-3.28c3.28-.49 6-3.31 6-6.72h-1.7z"/>`;
        };

        recognition.onerror = (event) => {
          console.error("Speech recognition error:", event.error);
          speak("Sorry, I didn't catch that. Please try again.");
        };
      }

      function initESP32Camera() {
        // Load the camera through the server proxy so the browser sees proper CORS headers
        esp32Feed.src = PROXIED_STREAM_URL;
        let hasLoaded = false;

        esp32Feed.onload = () => {
          if (hasLoaded) return;
          hasLoaded = true;

          setTimeout(() => {
            canvas.width = esp32Feed.naturalWidth || 640;
            canvas.height = esp32Feed.naturalHeight || 480;
            console.log(
              "Camera stream loaded. Canvas size set:",
              canvas.width,
              "x",
              canvas.height
            );

            isSystemReady = true;
            listenButton.disabled = false;
            speak("System ready. Tap to speak.");
          }, 500);
        };

        esp32Feed.onerror = () => {
          console.error("ESP32 Feed error!");
          speak(
            "Error: Could not load camera feed from server. Check server console."
          );
        };
      }

      function toggleListen() {
        if (!isSystemReady) {
          speak("Please wait for the system to initialize.");
          return;
        }

        if (isListening) {
          recognition.stop();
        } else {
          try {
            recognition.start();
            isListening = true;
            listenButton.classList.add("listening");
            micIcon.innerHTML = ` <path d="M12 12c-1.1 0-2-.9-2-2V6c0-1.1.9-2 2-2s2 .9 2 2v4c0 1.1-.9 2-2 2zm0-8c-2.21 0-4 1.79-4 4v4c0 2.21 1.79 4 4 4s4-1.79 4-4V8c0-2.21-1.79-4-4-4z"/><path d="M19 11h-1.7c0 3-2.54 5.1-5.3 5.1S6.7 14 6.7 11H5c0 3.41 2.72 6.23 6 6.72V21h2v-3.28c3.28-.49 6-3.31 6-6.72z"/>`;
            speak("Listening...");
          } catch (e) {
            console.error("Could not start listening:", e);
            isListening = false;
          }
        }
      }

      function processCommand(command) {
        if (command.includes("who")) {
          sendFrameToServer("who");
        } else if (command.includes("read")) {
          sendFrameToServer("read");
        } else if (command.includes("what")) {
          sendFrameToServer("what");
        } else {
          speak(`I heard "${command}", but I don't know that command.`);
        }
      }

      async function sendFrameToServer(command) {
        speak(`Processing your request to ${command}...`);
        console.log("LOG: Sending frame to server...");

        const context = canvas.getContext("2d");
        let imageData;
        try {
          // This should now work because of the crossorigin attribute
          context.drawImage(esp32Feed, 0, 0, canvas.width, canvas.height);
          imageData = canvas.toDataURL("image/jpeg", 0.8).split(",")[1];
        } catch (e) {
          console.error("Canvas drawImage error:", e); // This is where it failed last time
          speak(
            "Error capturing frame. Please check browser flags for insecure origins"
          );
          return;
        }

        try {
          const response = await fetch(SERVER_API_URL, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ command, image_b64: imageData }),
          });

          console.log("LOG: Got response from server");

          if (!response.ok)
            throw new Error(`Server error: ${response.statusText}`);

          const result = await response.json();
          speak(result.text);
        } catch (err) {
          console.error("LOG: Error fetching from server:", err);
          speak(
            "Sorry, I could not connect to the AI server. Please check the network."
          );
        }
      }

      window.onload = () => {
        initSpeechRecognition();
        initESP32Camera();
        listenButton.addEventListener("click", toggleListen);
        speak("Welcome to Assistive AI. Initializing system. Please wait.");
      };
    </script>
  </body>
</html>
